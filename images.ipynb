{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Ys2dCmzy163gqBZywTrkTYUqR1YdpOG",
      "authorship_tag": "ABX9TyPXRqe5YxIpnSIADBeSiwKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruthi2905/Real-vs-AI-generated-classification/blob/main/images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wsWWVTdrTSvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content/drive/MyDrive/Kaggle'"
      ],
      "metadata": {
        "id": "kLaCgLffBfJk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zv7v2FnCdsp",
        "outputId": "d25948d7-bcb0-4aaf-ecdf-533cf1bdecbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Kaggle\n",
            "/content/drive/MyDrive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.applications import DenseNet121, ResNet50 ,VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "import shutil"
      ],
      "metadata": {
        "id": "GIQDLRFc2c5_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data:\n",
        "    def _subset_directory(self, input_dir, max_images_per_class=50):\n",
        "        subset_dir = input_dir + '_subset'\n",
        "        if os.path.exists(subset_dir):\n",
        "            shutil.rmtree(subset_dir)\n",
        "        os.makedirs(subset_dir, exist_ok=True)\n",
        "        for class_name in os.listdir(input_dir):\n",
        "            class_path = os.path.join(input_dir, class_name)\n",
        "            subset_class_path = os.path.join(subset_dir, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "            os.makedirs(subset_class_path, exist_ok=True)\n",
        "            image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "            subset_files = image_files[:max_images_per_class]\n",
        "            for img_file in subset_files:\n",
        "                src_path = os.path.join(class_path, img_file)\n",
        "                dst_path = os.path.join(subset_class_path, img_file)\n",
        "                shutil.copy(src_path, dst_path)\n",
        "        return subset_dir\n",
        ""
      ],
      "metadata": {
        "id": "WRR_B_JRpD3a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj=Data()\n",
        "train_dir = obj._subset_directory('/content/drive/MyDrive/imgdata/data/Images/real_vs_fake/realvsfake/train',max_images_per_class=500)\n",
        "val_dir = obj._subset_directory('/content/drive/MyDrive/imgdata/data/Images/real_vs_fake/realvsfake/valid',max_images_per_class=500)\n",
        "test_dir = obj._subset_directory('/content/drive/MyDrive/imgdata/data/Images/real_vs_fake/realvsfake/test',max_images_per_class=500)"
      ],
      "metadata": {
        "id": "FCKgXO92pL_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train_dir Subfolders: \", os.listdir(train_dir))\n",
        "print(\"Valid_dir Subfolders: \", os.listdir(val_dir))\n",
        "print(\"Test_dir Subfolders: \", os.listdir(test_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exASxASwp0Ib",
        "outputId": "6d34d557-a3a2-43d8-e485-0d0b11bea084"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_dir Subfolders:  ['fake', 'real']\n",
            "Valid_dir Subfolders:  ['fake', 'real']\n",
            "Test_dir Subfolders:  ['fake', 'real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "target_size = (256,256)\n",
        "batch_size = 32  # Update this according to your batch size\n",
        "\n",
        "# Load data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Ensure test data is not shuffled\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbtXSwQrsu5A",
        "outputId": "3183c161-9561-4c0e-cd83-e5478aaae63b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify class distribution\n",
        "print(\"Training class distribution:\", train_generator.class_indices)\n",
        "print(\"Validation class distribution:\", val_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_F9anRrs7N5",
        "outputId": "5cd78c92-16e8-48cf-db76-b00251d8646b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class distribution: {'fake': 0, 'real': 1}\n",
            "Validation class distribution: {'fake': 0, 'real': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a0vkYuzs_n-",
        "outputId": "7c040602-9383-4753-c0c9-251150e64931"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom layers on top of VGG16\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "#x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers[-3:]:  # Unfreeze the last 4 layers (customize this as needed)\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model after making layers trainable\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # You can reduce the learning rate further if needed\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "I40BEOgctEMY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    #ModelCheckpoint('vgg16_best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=1e-6),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "]"
      ],
      "metadata": {
        "id": "9iO2-hwuwvS_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=4,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQkM7hfwww-K",
        "outputId": "1c1d4e32-4545-437b-ae31-cff87effbfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            " 1/32 [..............................] - ETA: 28:47 - loss: 0.6660 - accuracy: 0.5625"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensorflow.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrcLMTdLzXqJ",
        "outputId": "d52a30e3-9c2f-41e3-f4bc-7f162d3187bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = model.evaluate(test_generator)\n",
        "print(\"Test metrics:\", test_metrics[1])"
      ],
      "metadata": {
        "id": "Y7tW1ST6w2B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dqpsa52jxAvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VZBouMAJxDn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions on the test set\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# The model output is the probability of the image being real\n",
        "# Convert probabilities to percentage\n",
        "predicted_percentages = predictions * 100\n",
        "\n",
        "# Convert to predicted classes with a threshold of 50%\n",
        "predicted_classes = np.where(predicted_percentages > 50, 1, 0)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ],
      "metadata": {
        "id": "Ahdoq3-gyS-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Generate the confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# 4. Plot the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6t-xAteeyXly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    # Load image\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "    # Convert image to array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Rescale the image\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img, img_array\n",
        "\n",
        "img_path = 'data/Images/real_vs_fake/realvsfake/test/real/00093.jpg'\n",
        "target_size = (256, 256)  # Make sure this matches your model's input size\n",
        "\n",
        "# Load and preprocess the image\n",
        "img, img_array = load_and_preprocess_image(img_path, target_size)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Get the percentage for both classes\n",
        "real_confidence = prediction[0][0] * 100\n",
        "fake_confidence = (1 - prediction[0][0]) * 100\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n",
        "# Print the results\n",
        "print(f\"The model predicts this image is 'real' with a confidence of {real_confidence:.2f}%.\")\n",
        "print(f\"The model predicts this image is 'fake' with a confidence of {fake_confidence:.2f}%.\")"
      ],
      "metadata": {
        "id": "6vjl0vA6yeJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}